{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels to be hot encoded\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a decaying learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003        \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper parameters\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "\n",
    "# Define a consistent optimiser\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jialu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "##### Create a Neural Network with three hidden layers, batch normalisation, and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 32, 32, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32, 32, 1024)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32, 32, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32, 32, 256)       262400    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32, 32, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                655370    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 943,690\n",
      "Trainable params: 941,002\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "\n",
    "mlp.add(Dense(1024, input_shape=x_train.shape[1:]))\n",
    "mlp.add(Activation('elu'))\n",
    "mlp.add(BatchNormalization())\n",
    "mlp.add(Dropout(0.25))\n",
    "\n",
    "mlp.add(Dense(256))\n",
    "mlp.add(Activation('elu'))\n",
    "mlp.add(BatchNormalization())\n",
    "mlp.add(Dropout(0.25))\n",
    "\n",
    "mlp.add(Dense(64))\n",
    "mlp.add(Activation('elu'))\n",
    "mlp.add(BatchNormalization())\n",
    "mlp.add(Dropout(0.25))\n",
    "\n",
    "mlp.add(Flatten())\n",
    "mlp.add(Dense(10))\n",
    "mlp.add(Activation('softmax'))\n",
    "\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 9.9650 - acc: 0.3450 - val_loss: 9.5631 - val_acc: 0.3870\n",
      "Epoch 2/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 9.5149 - acc: 0.3900 - val_loss: 9.3319 - val_acc: 0.4023\n",
      "Epoch 3/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 9.1826 - acc: 0.4136 - val_loss: 9.5872 - val_acc: 0.3882\n",
      "Epoch 4/20\n",
      "781/781 [==============================] - 61s 78ms/step - loss: 9.1212 - acc: 0.4196 - val_loss: 9.1786 - val_acc: 0.4150\n",
      "Epoch 5/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.8913 - acc: 0.4338 - val_loss: 9.0061 - val_acc: 0.4239\n",
      "Epoch 6/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 8.7279 - acc: 0.4442 - val_loss: 8.8194 - val_acc: 0.4377\n",
      "Epoch 7/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.7012 - acc: 0.4474 - val_loss: 8.9921 - val_acc: 0.4294\n",
      "Epoch 8/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 8.6817 - acc: 0.4488 - val_loss: 8.8541 - val_acc: 0.4383\n",
      "Epoch 9/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 8.5741 - acc: 0.4555 - val_loss: 8.8584 - val_acc: 0.4398\n",
      "Epoch 10/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.5184 - acc: 0.4600 - val_loss: 8.6268 - val_acc: 0.4513\n",
      "Epoch 11/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.4118 - acc: 0.4658 - val_loss: 8.5621 - val_acc: 0.4560\n",
      "Epoch 12/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.3974 - acc: 0.4677 - val_loss: 8.5850 - val_acc: 0.4553\n",
      "Epoch 13/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 8.3946 - acc: 0.4679 - val_loss: 8.7946 - val_acc: 0.4431\n",
      "Epoch 14/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.3457 - acc: 0.4708 - val_loss: 9.1344 - val_acc: 0.4218\n",
      "Epoch 15/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.2706 - acc: 0.4751 - val_loss: 8.5668 - val_acc: 0.4564\n",
      "Epoch 16/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 8.1901 - acc: 0.4809 - val_loss: 8.5246 - val_acc: 0.4596\n",
      "Epoch 17/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 8.2338 - acc: 0.4780 - val_loss: 8.4482 - val_acc: 0.4628\n",
      "Epoch 18/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.0508 - acc: 0.4890 - val_loss: 8.4750 - val_acc: 0.4606\n",
      "Epoch 19/20\n",
      "781/781 [==============================] - 62s 79ms/step - loss: 8.1411 - acc: 0.4838 - val_loss: 8.9860 - val_acc: 0.4317\n",
      "Epoch 20/20\n",
      "781/781 [==============================] - 61s 79ms/step - loss: 7.9857 - acc: 0.4925 - val_loss: 8.5228 - val_acc: 0.4584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e0e568eb8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen_mlp = ImageDataGenerator()\n",
    "datagen_mlp.fit(x_train)\n",
    "\n",
    "mlp.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "mlp.fit_generator(datagen_mlp.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size, epochs=20,\\\n",
    "                    verbose=1, validation_data=(x_test,y_test), callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "##### Create a convolutional neural network with 3 convolutional layers, batch normalisation, dropout and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This model is definitely plagiarised, so will need to edit it somehow, I can do that tomorrow.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/125\n",
      "781/781 [==============================] - 15s 20ms/step - loss: 1.8757 - acc: 0.4318 - val_loss: 1.5947 - val_acc: 0.5426\n",
      "Epoch 2/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.2779 - acc: 0.5947 - val_loss: 1.0920 - val_acc: 0.6763\n",
      "Epoch 3/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 1.0802 - acc: 0.6609 - val_loss: 0.9899 - val_acc: 0.6981\n",
      "Epoch 4/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.9764 - acc: 0.6972 - val_loss: 0.9168 - val_acc: 0.7287\n",
      "Epoch 5/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.9108 - acc: 0.7203 - val_loss: 0.8943 - val_acc: 0.7372\n",
      "Epoch 6/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8701 - acc: 0.7337 - val_loss: 1.0229 - val_acc: 0.7207\n",
      "Epoch 7/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8324 - acc: 0.7494 - val_loss: 0.9114 - val_acc: 0.7432\n",
      "Epoch 8/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.8083 - acc: 0.7574 - val_loss: 0.8229 - val_acc: 0.7659\n",
      "Epoch 9/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7871 - acc: 0.7697 - val_loss: 0.7451 - val_acc: 0.7889\n",
      "Epoch 10/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7678 - acc: 0.7751 - val_loss: 0.7305 - val_acc: 0.7954\n",
      "Epoch 11/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7486 - acc: 0.7838 - val_loss: 0.7869 - val_acc: 0.7777\n",
      "Epoch 12/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7409 - acc: 0.7888 - val_loss: 0.7593 - val_acc: 0.7905\n",
      "Epoch 13/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7344 - acc: 0.7927 - val_loss: 0.7227 - val_acc: 0.8004\n",
      "Epoch 14/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7154 - acc: 0.7969 - val_loss: 0.7327 - val_acc: 0.7990\n",
      "Epoch 15/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7112 - acc: 0.7997 - val_loss: 0.6685 - val_acc: 0.8207\n",
      "Epoch 16/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.7008 - acc: 0.8051 - val_loss: 0.6583 - val_acc: 0.8246\n",
      "Epoch 17/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6946 - acc: 0.8054 - val_loss: 0.6356 - val_acc: 0.8332\n",
      "Epoch 18/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6821 - acc: 0.8122 - val_loss: 0.7008 - val_acc: 0.8134\n",
      "Epoch 19/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6781 - acc: 0.8128 - val_loss: 0.6700 - val_acc: 0.8261\n",
      "Epoch 20/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6716 - acc: 0.8149 - val_loss: 0.6967 - val_acc: 0.8179\n",
      "Epoch 21/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6663 - acc: 0.8183 - val_loss: 0.7029 - val_acc: 0.8122\n",
      "Epoch 22/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6626 - acc: 0.8192 - val_loss: 0.6560 - val_acc: 0.8310\n",
      "Epoch 23/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6592 - acc: 0.8224 - val_loss: 0.6429 - val_acc: 0.8309\n",
      "Epoch 24/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6540 - acc: 0.8223 - val_loss: 0.7009 - val_acc: 0.8176\n",
      "Epoch 25/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6479 - acc: 0.8252 - val_loss: 0.6766 - val_acc: 0.8318\n",
      "Epoch 26/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6468 - acc: 0.8259 - val_loss: 0.6069 - val_acc: 0.8481\n",
      "Epoch 27/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6432 - acc: 0.8267 - val_loss: 0.6157 - val_acc: 0.8458\n",
      "Epoch 28/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6353 - acc: 0.8322 - val_loss: 0.6432 - val_acc: 0.8349\n",
      "Epoch 29/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6379 - acc: 0.8301 - val_loss: 0.5910 - val_acc: 0.8510\n",
      "Epoch 30/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6390 - acc: 0.8308 - val_loss: 0.6283 - val_acc: 0.8399\n",
      "Epoch 31/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6312 - acc: 0.8329 - val_loss: 0.6240 - val_acc: 0.8403\n",
      "Epoch 32/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6310 - acc: 0.8326 - val_loss: 0.6892 - val_acc: 0.8274\n",
      "Epoch 33/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6254 - acc: 0.8342 - val_loss: 0.6286 - val_acc: 0.8412\n",
      "Epoch 34/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6283 - acc: 0.8339 - val_loss: 0.6086 - val_acc: 0.8459\n",
      "Epoch 35/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6242 - acc: 0.8362 - val_loss: 0.6261 - val_acc: 0.8429\n",
      "Epoch 36/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6205 - acc: 0.8375 - val_loss: 0.6076 - val_acc: 0.8447\n",
      "Epoch 37/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6184 - acc: 0.8372 - val_loss: 0.6994 - val_acc: 0.8238\n",
      "Epoch 38/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6163 - acc: 0.8400 - val_loss: 0.6037 - val_acc: 0.8523\n",
      "Epoch 39/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6110 - acc: 0.8403 - val_loss: 0.6504 - val_acc: 0.8385\n",
      "Epoch 40/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6157 - acc: 0.8390 - val_loss: 0.5790 - val_acc: 0.8546\n",
      "Epoch 41/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6151 - acc: 0.8399 - val_loss: 0.6035 - val_acc: 0.8521\n",
      "Epoch 42/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6125 - acc: 0.8402 - val_loss: 0.6198 - val_acc: 0.8441\n",
      "Epoch 43/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6105 - acc: 0.8426 - val_loss: 0.6224 - val_acc: 0.8439\n",
      "Epoch 44/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6077 - acc: 0.8418 - val_loss: 0.7473 - val_acc: 0.8228\n",
      "Epoch 45/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6055 - acc: 0.8433 - val_loss: 0.6340 - val_acc: 0.8422\n",
      "Epoch 46/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6012 - acc: 0.8443 - val_loss: 0.6006 - val_acc: 0.8540\n",
      "Epoch 47/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6047 - acc: 0.8435 - val_loss: 0.5741 - val_acc: 0.8607\n",
      "Epoch 48/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5948 - acc: 0.8472 - val_loss: 0.5752 - val_acc: 0.8571\n",
      "Epoch 49/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.6017 - acc: 0.8440 - val_loss: 0.5596 - val_acc: 0.8618\n",
      "Epoch 50/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.6013 - acc: 0.8444 - val_loss: 0.6032 - val_acc: 0.8513\n",
      "Epoch 51/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5978 - acc: 0.8452 - val_loss: 0.6463 - val_acc: 0.8405\n",
      "Epoch 52/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5930 - acc: 0.8491 - val_loss: 0.6232 - val_acc: 0.8514\n",
      "Epoch 53/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5975 - acc: 0.8459 - val_loss: 0.6602 - val_acc: 0.8366\n",
      "Epoch 54/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5977 - acc: 0.8457 - val_loss: 0.6611 - val_acc: 0.8344\n",
      "Epoch 55/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5894 - acc: 0.8510 - val_loss: 0.6174 - val_acc: 0.8467\n",
      "Epoch 56/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5970 - acc: 0.8457 - val_loss: 0.6925 - val_acc: 0.8330\n",
      "Epoch 57/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5874 - acc: 0.8496 - val_loss: 0.5734 - val_acc: 0.8628\n",
      "Epoch 58/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5969 - acc: 0.8459 - val_loss: 0.6345 - val_acc: 0.8447\n",
      "Epoch 59/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5899 - acc: 0.8479 - val_loss: 0.6265 - val_acc: 0.8491\n",
      "Epoch 60/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5916 - acc: 0.8468 - val_loss: 0.5695 - val_acc: 0.8631\n",
      "Epoch 61/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5851 - acc: 0.8513 - val_loss: 0.6129 - val_acc: 0.8518\n",
      "Epoch 62/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5904 - acc: 0.8486 - val_loss: 0.5696 - val_acc: 0.8631\n",
      "Epoch 63/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5857 - acc: 0.8498 - val_loss: 0.7164 - val_acc: 0.8167\n",
      "Epoch 64/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5861 - acc: 0.8506 - val_loss: 0.5876 - val_acc: 0.8576\n",
      "Epoch 65/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5837 - acc: 0.8517 - val_loss: 0.5968 - val_acc: 0.8548\n",
      "Epoch 66/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5834 - acc: 0.8527 - val_loss: 0.6136 - val_acc: 0.8509\n",
      "Epoch 67/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5878 - acc: 0.8504 - val_loss: 0.5991 - val_acc: 0.8543\n",
      "Epoch 68/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5785 - acc: 0.8535 - val_loss: 0.5696 - val_acc: 0.8660\n",
      "Epoch 69/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5821 - acc: 0.8526 - val_loss: 0.5859 - val_acc: 0.8541\n",
      "Epoch 70/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5826 - acc: 0.8533 - val_loss: 0.6146 - val_acc: 0.8568\n",
      "Epoch 71/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5781 - acc: 0.8551 - val_loss: 0.6371 - val_acc: 0.8459\n",
      "Epoch 72/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5825 - acc: 0.8511 - val_loss: 0.5869 - val_acc: 0.8576\n",
      "Epoch 73/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5784 - acc: 0.8552 - val_loss: 0.6505 - val_acc: 0.8375\n",
      "Epoch 74/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5765 - acc: 0.8548 - val_loss: 0.5640 - val_acc: 0.8651\n",
      "Epoch 75/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5750 - acc: 0.8538 - val_loss: 0.6485 - val_acc: 0.8403\n",
      "Epoch 76/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5767 - acc: 0.8532 - val_loss: 0.6019 - val_acc: 0.8556\n",
      "Epoch 77/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.5323 - acc: 0.8685 - val_loss: 0.5428 - val_acc: 0.8690\n",
      "Epoch 78/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5176 - acc: 0.8728 - val_loss: 0.5603 - val_acc: 0.8708\n",
      "Epoch 79/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5058 - acc: 0.8757 - val_loss: 0.5326 - val_acc: 0.8725\n",
      "Epoch 80/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.5037 - acc: 0.8763 - val_loss: 0.5352 - val_acc: 0.8682\n",
      "Epoch 81/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4964 - acc: 0.8767 - val_loss: 0.4900 - val_acc: 0.8864\n",
      "Epoch 82/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4920 - acc: 0.8786 - val_loss: 0.5339 - val_acc: 0.8732\n",
      "Epoch 83/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4878 - acc: 0.8765 - val_loss: 0.5092 - val_acc: 0.8795\n",
      "Epoch 84/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4862 - acc: 0.8774 - val_loss: 0.5111 - val_acc: 0.8801\n",
      "Epoch 85/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4849 - acc: 0.8785 - val_loss: 0.5019 - val_acc: 0.8769\n",
      "Epoch 86/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4824 - acc: 0.8779 - val_loss: 0.4936 - val_acc: 0.8825\n",
      "Epoch 87/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4736 - acc: 0.8796 - val_loss: 0.5103 - val_acc: 0.8773\n",
      "Epoch 88/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4730 - acc: 0.8800 - val_loss: 0.5081 - val_acc: 0.8778\n",
      "Epoch 89/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4731 - acc: 0.8790 - val_loss: 0.4994 - val_acc: 0.8795\n",
      "Epoch 90/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4716 - acc: 0.8796 - val_loss: 0.5069 - val_acc: 0.8758\n",
      "Epoch 91/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4722 - acc: 0.8797 - val_loss: 0.5146 - val_acc: 0.8762\n",
      "Epoch 92/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4697 - acc: 0.8814 - val_loss: 0.4944 - val_acc: 0.8759\n",
      "Epoch 93/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4600 - acc: 0.8824 - val_loss: 0.5020 - val_acc: 0.8763\n",
      "Epoch 94/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4632 - acc: 0.8817 - val_loss: 0.4919 - val_acc: 0.8795\n",
      "Epoch 95/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4622 - acc: 0.8805 - val_loss: 0.5015 - val_acc: 0.8778\n",
      "Epoch 96/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4543 - acc: 0.8843 - val_loss: 0.4959 - val_acc: 0.8795\n",
      "Epoch 97/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4613 - acc: 0.8826 - val_loss: 0.5029 - val_acc: 0.8814\n",
      "Epoch 98/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4585 - acc: 0.8813 - val_loss: 0.4916 - val_acc: 0.8797\n",
      "Epoch 99/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4604 - acc: 0.8810 - val_loss: 0.4954 - val_acc: 0.8787\n",
      "Epoch 100/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4562 - acc: 0.8832 - val_loss: 0.5018 - val_acc: 0.8769\n",
      "Epoch 101/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4606 - acc: 0.8813 - val_loss: 0.5101 - val_acc: 0.8755\n",
      "Epoch 102/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4585 - acc: 0.8809 - val_loss: 0.5172 - val_acc: 0.8757\n",
      "Epoch 103/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4551 - acc: 0.8826 - val_loss: 0.4848 - val_acc: 0.8786\n",
      "Epoch 104/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4513 - acc: 0.8828 - val_loss: 0.4997 - val_acc: 0.8765\n",
      "Epoch 105/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4487 - acc: 0.8846 - val_loss: 0.5123 - val_acc: 0.8762\n",
      "Epoch 106/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4500 - acc: 0.8832 - val_loss: 0.4971 - val_acc: 0.8783\n",
      "Epoch 107/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4519 - acc: 0.8818 - val_loss: 0.5025 - val_acc: 0.8786\n",
      "Epoch 108/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4530 - acc: 0.8812 - val_loss: 0.4797 - val_acc: 0.8790\n",
      "Epoch 109/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4458 - acc: 0.8852 - val_loss: 0.4655 - val_acc: 0.8905\n",
      "Epoch 110/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4513 - acc: 0.8832 - val_loss: 0.5135 - val_acc: 0.8717\n",
      "Epoch 111/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4453 - acc: 0.8852 - val_loss: 0.4625 - val_acc: 0.8861\n",
      "Epoch 112/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4453 - acc: 0.8854 - val_loss: 0.4788 - val_acc: 0.8837\n",
      "Epoch 113/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4471 - acc: 0.8834 - val_loss: 0.4922 - val_acc: 0.8799\n",
      "Epoch 114/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4502 - acc: 0.8832 - val_loss: 0.4663 - val_acc: 0.8867\n",
      "Epoch 115/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4481 - acc: 0.8836 - val_loss: 0.4722 - val_acc: 0.8855\n",
      "Epoch 116/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4494 - acc: 0.8812 - val_loss: 0.5511 - val_acc: 0.8618\n",
      "Epoch 117/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4474 - acc: 0.8845 - val_loss: 0.4893 - val_acc: 0.8797\n",
      "Epoch 118/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4459 - acc: 0.8859 - val_loss: 0.4595 - val_acc: 0.8870\n",
      "Epoch 119/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4483 - acc: 0.8852 - val_loss: 0.4962 - val_acc: 0.8780\n",
      "Epoch 120/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4431 - acc: 0.8860 - val_loss: 0.4818 - val_acc: 0.8852\n",
      "Epoch 121/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4439 - acc: 0.8849 - val_loss: 0.4647 - val_acc: 0.8869\n",
      "Epoch 122/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4434 - acc: 0.8849 - val_loss: 0.4883 - val_acc: 0.8809\n",
      "Epoch 123/125\n",
      "781/781 [==============================] - 14s 18ms/step - loss: 0.4447 - acc: 0.8836 - val_loss: 0.4615 - val_acc: 0.8879\n",
      "Epoch 124/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4439 - acc: 0.8841 - val_loss: 0.4832 - val_acc: 0.8805\n",
      "Epoch 125/125\n",
      "781/781 [==============================] - 14s 17ms/step - loss: 0.4409 - acc: 0.8860 - val_loss: 0.4843 - val_acc: 0.8809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d5e5a4d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 101us/step\n",
      "\n",
      "Test result: 88.090 loss: 0.484\n"
     ]
    }
   ],
   "source": [
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5') \n",
    " \n",
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2040ebebb641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_train_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_new = np.zeros(shape=(x_train.shape[0], 224, 224, 3))\n",
    "for idx in xrange(X_train.shape[0]):\n",
    "    X_train_new[idx] = X_train[idx].reshape(224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, None, None, 2 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           10250       activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 25,696,138\n",
      "Trainable params: 25,643,018\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024)(x)\n",
    "x = Activation('elu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "resnet_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers: \n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "batch_size = 64\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "resnet_model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "resnet_model.fit_generator(datagen.flow(x_train_new, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=10,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
